{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Eng-Daw.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbtxGNL4MPk1++XUZoEMZC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atnafuatx/atx/blob/master/Eng_Daw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq_VM7emG8iQ",
        "outputId": "037d2290-aa87-48e2-ee4e-528490c69a74"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7T5j2qSJzqj"
      },
      "source": [
        "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\r\n",
        "# These will also become the suffix's of all vocab and corpus files used throughout\r\n",
        "import os\r\n",
        "source_language = \"en\"\r\n",
        "target_language = \"daw\"\r\n",
        "tag = \"baseline\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\r\n",
        "\r\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\r\n",
        "os.environ[\"tgt\"] = target_language\r\n",
        "os.environ[\"tag\"] = tag\r\n",
        "\r\n",
        "# This will save it to a folder in our gdrive instead!\r\n",
        "!mkdir -p \"/content/drive/My Drive/dawromodel/$src-$tgt\"\r\n",
        "os.environ[\"gdrive_path\"] = \"/content/drive/My Drive/dawromodel/%s-%s\" % (source_language, target_language)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "pbYLDS9NJ1kK",
        "outputId": "1fe6bc13-827a-4d5e-f84f-b1f2c327e588"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1d455197-9f02-407b-84e1-648de348d406\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1d455197-9f02-407b-84e1-648de348d406\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving eng-daw.csv to eng-daw (2).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkchS8XxJ3Wd"
      },
      "source": [
        "import pandas as pd\r\n",
        "import io\r\n",
        "data = pd.read_csv(io.BytesIO(uploaded['eng-daw.csv']), encoding='cp1252')\r\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "EO1g7JrmJ5lD",
        "outputId": "86a8fc78-6ec6-42dd-9e6a-29e7391cd292"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Dawuro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is the family history of Jesus the Messia...</td>\n",
              "      <td>Hawe Daawita zariyaanne Abraahaame zare gideed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abraham was the father of Isaac. Isaac was the...</td>\n",
              "      <td>Abraahaame, Yisaaqa yeleedda; Yisaaqi, Yayiqoo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Judah was the father of Perez and Zerah. (Thei...</td>\n",
              "      <td>Yihuday Ti7imaarippe Paareesanne Zaraahaa yele...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ram was the father of Amminadab. Amminadab was...</td>\n",
              "      <td>Raame Aminadaaba yeleedda; Aminadaabe, Na7asoo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Salmon was the father of Boaz. (His mother was...</td>\n",
              "      <td>Selimoone, Ra7aabo geetettiyaa mishirattippe B...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             English                                             Dawuro\n",
              "0  This is the family history of Jesus the Messia...  Hawe Daawita zariyaanne Abraahaame zare gideed...\n",
              "1  Abraham was the father of Isaac. Isaac was the...  Abraahaame, Yisaaqa yeleedda; Yisaaqi, Yayiqoo...\n",
              "2  Judah was the father of Perez and Zerah. (Thei...  Yihuday Ti7imaarippe Paareesanne Zaraahaa yele...\n",
              "3  Ram was the father of Amminadab. Amminadab was...  Raame Aminadaaba yeleedda; Aminadaabe, Na7asoo...\n",
              "4  Salmon was the father of Boaz. (His mother was...  Selimoone, Ra7aabo geetettiyaa mishirattippe B..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze7kCz5YJ8Jo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "6a5af499-cdad-4b09-f4a0-93395e0d6921"
      },
      "source": [
        "data[data.duplicated()]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Dawuro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1575</th>\n",
              "      <td>The whole world, earth and sky, will be destro...</td>\n",
              "      <td>Saluunne sa7ay aadhdhana; shin ta qaalay ubbak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7460</th>\n",
              "      <td>Everyone who hears this should listen to what ...</td>\n",
              "      <td>‘Sisanaw haythay de7iyaa uray Geeshsha Ayyaana...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                English                                             Dawuro\n",
              "1575  The whole world, earth and sky, will be destro...  Saluunne sa7ay aadhdhana; shin ta qaalay ubbak...\n",
              "7460  Everyone who hears this should listen to what ...  ‘Sisanaw haythay de7iyaa uray Geeshsha Ayyaana..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuPbRGAQJ_TI"
      },
      "source": [
        "data = data.rename(columns={\"English\":\"source_sentence\", \"Dawuro\":\"target_sentence\"})"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snDIFR-2KB_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5bac29-4faa-4e89-a5f7-234d53c9100d"
      },
      "source": [
        "print(\"Length of Data before Removing duplicate: \",len(data))\r\n",
        "data = data.drop_duplicates()\r\n",
        "print(\"Length of Data after Removing duplicate: \",len(data))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Data before Removing duplicate:  7804\n",
            "Length of Data after Removing duplicate:  7802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qm6Hc9eKDoV"
      },
      "source": [
        "# Do the split between dev/test/train and create parallel corpora\r\n",
        "num_dev_patterns = 1000\r\n",
        "num_test_patterns = 1000\r\n",
        "df = data\r\n",
        "# Lower case the corpora\r\n",
        "df[\"source_sentence\"] = df[\"source_sentence\"].str.lower()\r\n",
        "df[\"target_sentence\"] = df[\"target_sentence\"].str.lower()\r\n",
        "\r\n",
        "\r\n",
        "devtest = df.tail(num_dev_patterns + num_test_patterns)\r\n",
        "test = devtest.tail(num_test_patterns)\r\n",
        "dev = devtest.head(num_dev_patterns)\r\n",
        "stripped = df.drop(df.tail(num_dev_patterns + num_test_patterns).index)\r\n",
        "\r\n",
        "stripped[[\"source_sentence\"]].to_csv(\"train.en\", index=False)\r\n",
        "stripped[[\"target_sentence\"]].to_csv(\"train.daw\", index=False)\r\n",
        "\r\n",
        "dev[[\"source_sentence\"]].to_csv(\"dev.en\", index=False)\r\n",
        "dev[[\"target_sentence\"]].to_csv(\"dev.daw\", index=False)\r\n",
        "\r\n",
        "test[[\"source_sentence\"]].to_csv(\"test.en\", index=False)\r\n",
        "test[[\"target_sentence\"]].to_csv(\"test.daw\", index=False)\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phexMiw9KFNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f434f4-7978-4aea-ad8c-f075d3f24450"
      },
      "source": [
        "\r\n",
        "# Install JoeyNMT\r\n",
        "! git clone https://github.com/joeynmt/joeynmt.git\r\n",
        "! cd joeynmt; pip3 install ."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'joeynmt' already exists and is not an empty directory.\n",
            "Processing /content/joeynmt\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (7.0.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (1.18.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (51.0.0)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (1.6.0)\n",
            "Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (2.4.0)\n",
            "Requirement already satisfied: torchtext<0.8.0 in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (0.3.1)\n",
            "Requirement already satisfied: sacrebleu>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (1.4.14)\n",
            "Requirement already satisfied: subword-nmt in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (0.3.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (0.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (5.3.1)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (2.6.0)\n",
            "Requirement already satisfied: six==1.12 in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (1.12.0)\n",
            "Requirement already satisfied: wrapt==1.11.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt==1.0) (1.11.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15->joeynmt==1.0) (1.32.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15->joeynmt==1.0) (0.4.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15->joeynmt==1.0) (3.12.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15->joeynmt==1.0) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15->joeynmt==1.0) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15->joeynmt==1.0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15->joeynmt==1.0) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15->joeynmt==1.0) (0.36.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15->joeynmt==1.0) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15->joeynmt==1.0) (0.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext<0.8.0->joeynmt==1.0) (4.41.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.3.6->joeynmt==1.0) (2.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==1.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==1.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==1.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==1.0) (2.4.7)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==1.0) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==1.0) (1.4.1)\n",
            "Requirement already satisfied: isort<6,>=4.2.5 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt==1.0) (5.6.4)\n",
            "Requirement already satisfied: astroid<=2.5,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt==1.0) (2.4.2)\n",
            "Requirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt==1.0) (0.10.2)\n",
            "Requirement already satisfied: mccabe<0.7,>=0.6 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt==1.0) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->joeynmt==1.0) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.0) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.0) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.15->joeynmt==1.0) (3.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.0) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn->joeynmt==1.0) (2018.9)\n",
            "Requirement already satisfied: lazy-object-proxy==1.4.* in /usr/local/lib/python3.6/dist-packages (from astroid<=2.5,>=2.4.0->pylint->joeynmt==1.0) (1.4.3)\n",
            "Requirement already satisfied: typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from astroid<=2.5,>=2.4.0->pylint->joeynmt==1.0) (1.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->joeynmt==1.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.15->joeynmt==1.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.15->joeynmt==1.0) (3.7.4.3)\n",
            "Building wheels for collected packages: joeynmt\n",
            "  Building wheel for joeynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for joeynmt: filename=joeynmt-1.0-cp36-none-any.whl size=80253 sha256=b4cc55bef2af283ca1b228ad41d9e3e59f954089e487e833916338ddb0c1f654\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n1enlju5/wheels/db/01/db/751cc9f3e7f6faec127c43644ba250a3ea7ad200594aeda70a\n",
            "Successfully built joeynmt\n",
            "Installing collected packages: joeynmt\n",
            "  Found existing installation: joeynmt 1.0\n",
            "    Uninstalling joeynmt-1.0:\n",
            "      Successfully uninstalled joeynmt-1.0\n",
            "Successfully installed joeynmt-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0v2JhPoKIhJ",
        "outputId": "82de4b0f-1d8e-4a38-cdda-f4ef133c1f3d"
      },
      "source": [
        "# One of the huge boosts in NMT performance was to use a different method of tokenizing. \r\n",
        "# Usually, NMT would tokenize by words. However, using a method called BPE gave amazing boosts to performance\r\n",
        "\r\n",
        "# Do subword NMT\r\n",
        "! mkdir joeynmt/data/\r\n",
        "! mkdir joeynmt/data/endaw/\r\n",
        "! export data_path=joeynmt/data/$src$tgt/\r\n",
        "! subword-nmt learn-joint-bpe-and-vocab --input train.$src train.$tgt -s 4000 -o bpe.codes.4000 --write-vocabulary vocab.$src vocab.$tgt\r\n",
        "\r\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < train.$src > train.bpe.$src\r\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < train.$tgt > train.bpe.$tgt\r\n",
        "\r\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < dev.$src > dev.bpe.$src\r\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < dev.$tgt > dev.bpe.$tgt\r\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < test.$src > test.bpe.$src\r\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < test.$tgt > test.bpe.$tgt\r\n",
        "\r\n",
        "# Create directory, move everyone we care about to the correct location\r\n",
        "#! mkdir -p $data_path\r\n",
        "! cp train.* joeynmt/data/endaw/\r\n",
        "! cp test.* joeynmt/data/endaw/\r\n",
        "! cp dev.* joeynmt/data/endaw/\r\n",
        "! cp bpe.codes.4000 $data_path\r\n",
        "! ls $data_path\r\n",
        "\r\n",
        "# Create that vocab using build_vocab\r\n",
        "! sudo chmod 777 joeynmt/scripts/build_vocab.py\r\n",
        "! joeynmt/scripts/build_vocab.py joeynmt/data/$src$tgt/train.bpe.$src joeynmt/data/$src$tgt/train.bpe.$tgt --output_path joeynmt/data/$src$tgt/vocab.txt\r\n",
        "\r\n",
        "# Some output\r\n",
        "! echo \"BPE Dawro Sentences\"\r\n",
        "! tail -n 5 test.bpe.$tgt\r\n",
        "! echo \"Combined BPE Vocab\"\r\n",
        "! tail -n 10 joeynmt/data/endaw/vocab.txt\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘joeynmt/data/’: File exists\n",
            "mkdir: cannot create directory ‘joeynmt/data/endaw/’: File exists\n",
            "cp: missing destination file operand after 'bpe.codes.4000'\n",
            "Try 'cp --help' for more information.\n",
            " bpe.codes.4000   drive\t\t     sample_data    train.bpe.daw   vocab.en\n",
            " dev.bpe.daw\t 'eng-daw (1).csv'   test.bpe.daw   train.bpe.en\n",
            " dev.bpe.en\t 'eng-daw (2).csv'   test.bpe.en    train.daw\n",
            " dev.daw\t  eng-daw.csv\t     test.daw\t    train.en\n",
            " dev.en\t\t  joeynmt\t     test.en\t    vocab.daw\n",
            "BPE Dawro Sentences\n",
            "\"@@ geeshsha ayyaan@@ aynne ge@@ le@@ w@@ un@@ na, “@@ haa y@@ a” yaag@@ iino. qassi hawaa sis@@ iya@@ we oon@@ inne, “@@ haa y@@ a” yaa@@ go. saa@@ mett@@ eedda asay ooninne haa yo@@ . de7@@ uwa haathaa koyyiyaa asay ooninne coo akk@@ o. \"\n",
            "\"taani ha maxaaf@@ an xaaf@@ etteedda han@@ ana geedda qaalaa sis@@ iyaa oonanne zor@@ ay. ooninne ha qaalaa bolla itti@@ baa gujj@@ ooppe, xoossay ha maxaaf@@ an xaaf@@ etteedda bo@@ sh@@ aa a bolla gujj@@ ana. \"\n",
            "\"ooninne maxaaf@@ an de7iya timbbit@@ iyaa qaal@@ aappe ay@@ anne p@@ ac@@ iss@@ ooppe, ha maxaaf@@ aa giddon qoncc@@ iss@@ eedda de7@@ uwa mithaa ayf@@ iyaa@@ ppenne geeshsha katamaappe a gakk@@ iya gi@@ sh@@ uwaa xoossay p@@ ac@@ iss@@ ana. \"\n",
            "\"ha ubbab@@ aw markkatt@@ iyaawe, “@@ tuma@@ ! taani ellekka yaan@@ a” yaagee. am@@ en@@ 77@@ i. godaa yesuus@@ aa, neeni haa@@ y@@ a. \"\n",
            "godaa yesuusi kiristtoosa aadho keekat@@ ethay hintten@@ aanna ubb@@ aanna gid@@ o. am@@ en@@ 77@@ i.\n",
            "Combined BPE Vocab\n",
            "mir@@\n",
            "adul@@\n",
            "cei@@\n",
            "ell\n",
            "medi@@\n",
            "anti@@\n",
            "paas@@\n",
            "xamma@@\n",
            "rou@@\n",
            "if@@\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wr88g9nKLAc",
        "outputId": "ec017068-ee9b-49a2-a253-f76290068a37"
      },
      "source": [
        "\r\n",
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\r\n",
        "! cp train.* \"$gdrive_path\"\r\n",
        "! cp test.* \"$gdrive_path\"\r\n",
        "! cp dev.* \"$gdrive_path\"\r\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\r\n",
        "! ls \"$gdrive_path\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.daw  models        test.daw  train.bpe.daw\ttrain.en\n",
            "dev.bpe.daw\tdev.en\t test.bpe.daw  test.en\t train.bpe.en\ttrain.om\n",
            "dev.bpe.en\tdev.om\t test.bpe.en   test.om\t train.daw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y36hbiakKO5i"
      },
      "source": [
        "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\r\n",
        "# (You can of course play with all the parameters if you'd like!)\r\n",
        "name = '%s%s' % (source_language, target_language)\r\n",
        "\r\n",
        "config = \"\"\"\r\n",
        "name: \"{name}_transformer\"\r\n",
        "\r\n",
        "data:\r\n",
        "    src: \"{source_language}\"\r\n",
        "    trg: \"{target_language}\"\r\n",
        "    train: \"data/{name}/train.bpe\"\r\n",
        "    dev:   \"data/{name}/dev.bpe\"\r\n",
        "    test:  \"data/{name}/test.bpe\"\r\n",
        "    level: \"bpe\"\r\n",
        "    lowercase: False\r\n",
        "    max_sent_length: 100\r\n",
        "    src_vocab: \"data/{name}/vocab.txt\"\r\n",
        "    trg_vocab: \"data/{name}/vocab.txt\"\r\n",
        "\r\n",
        "testing:\r\n",
        "    beam_size: 5\r\n",
        "    alpha: 1.0\r\n",
        "\r\n",
        "training:\r\n",
        "    #load_model: \"models/{name}_transformer/12000.ckpt\" # if given, load a pre-trained model from this checkpoint\r\n",
        "    random_seed: 42\r\n",
        "    optimizer: \"adam\"\r\n",
        "    normalization: \"tokens\"\r\n",
        "    adam_betas: [0.9, 0.999] \r\n",
        "    scheduling: \"noam\"            # Try switching from plateau to Noam scheduling\r\n",
        "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\r\n",
        "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\r\n",
        "    patience: 8\r\n",
        "    decrease_factor: 0.7\r\n",
        "    loss: \"crossentropy\"\r\n",
        "    learning_rate: 0.0002\r\n",
        "    learning_rate_min: 0.00000001\r\n",
        "    weight_decay: 0.0\r\n",
        "    label_smoothing: 0.1\r\n",
        "    batch_size: 4096\r\n",
        "    batch_type: \"token\"\r\n",
        "    eval_batch_size: 3600\r\n",
        "    eval_batch_type: \"token\"\r\n",
        "    batch_multiplier: 1\r\n",
        "    early_stopping_metric: \"ppl\"\r\n",
        "    epochs: 10 #14  TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\r\n",
        "    validation_freq: 400 # Decrease this for testing\r\n",
        "    logging_freq: 100\r\n",
        "    eval_metric: \"bleu\"\r\n",
        "    model_dir: \"models/{name}_transformer\"\r\n",
        "    overwrite: True\r\n",
        "    shuffle: True\r\n",
        "    use_cuda: True\r\n",
        "    max_output_length: 100\r\n",
        "    print_valid_sents: [0, 1, 2, 3]\r\n",
        "    keep_last_ckpts: 3\r\n",
        "\r\n",
        "model:\r\n",
        "    initializer: \"xavier\"\r\n",
        "    bias_initializer: \"zeros\"\r\n",
        "    init_gain: 1.0\r\n",
        "    embed_initializer: \"xavier\"\r\n",
        "    embed_init_gain: 1.0\r\n",
        "    tied_embeddings: True\r\n",
        "    tied_softmax: True\r\n",
        "    encoder:\r\n",
        "        type: \"transformer\"\r\n",
        "        num_layers: 6\r\n",
        "        num_heads: 8\r\n",
        "        embeddings:\r\n",
        "            embedding_dim: 512\r\n",
        "            scale: True\r\n",
        "            dropout: 0.\r\n",
        "        # typically ff_size = 4 x hidden_size\r\n",
        "        hidden_size: 512\r\n",
        "        ff_size: 2048\r\n",
        "        dropout: 0.3\r\n",
        "    decoder:\r\n",
        "        type: \"transformer\"\r\n",
        "        num_layers: 6\r\n",
        "        num_heads: 8\r\n",
        "        embeddings:\r\n",
        "            embedding_dim: 512\r\n",
        "            scale: True\r\n",
        "            dropout: 0.\r\n",
        "        # typically ff_size = 4 x hidden_size\r\n",
        "        hidden_size: 512\r\n",
        "        ff_size: 2048\r\n",
        "        dropout: 0.3\r\n",
        "\"\"\".format(name=name, source_language=source_language, target_language=target_language)\r\n",
        "with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=name),'w') as f:\r\n",
        "    f.write(config)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF6OJN58KRXR",
        "outputId": "b9a768e4-c940-4760-c2aa-4af101004bf4"
      },
      "source": [
        "!cd joeynmt; python3 -m joeynmt train configs/transformer_$src$tgt.yaml"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-23 16:29:32,456 - INFO - root - Hello! This is Joey-NMT (version 1.0).\n",
            "2020-12-23 16:29:32,459 - INFO - joeynmt.data - loading training data...\n",
            "2020-12-23 16:29:32,529 - INFO - joeynmt.data - building vocabulary...\n",
            "2020-12-23 16:29:32,721 - INFO - joeynmt.data - loading dev data...\n",
            "2020-12-23 16:29:32,732 - INFO - joeynmt.data - loading test data...\n",
            "2020-12-23 16:29:32,746 - INFO - joeynmt.data - data loaded.\n",
            "2020-12-23 16:29:33.549566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-23 16:29:34,913 - INFO - joeynmt.training - Total params: 46190080\n",
            "2020-12-23 16:29:34,916 - INFO - joeynmt.helpers - cfg.name                           : endaw_transformer\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.data.src                       : en\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.data.trg                       : daw\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.data.train                     : data/endaw/train.bpe\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.data.dev                       : data/endaw/dev.bpe\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.data.test                      : data/endaw/test.bpe\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.data.level                     : bpe\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 100\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.data.src_vocab                 : data/endaw/vocab.txt\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.data.trg_vocab                 : data/endaw/vocab.txt\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]\n",
            "2020-12-23 16:29:34,917 - INFO - joeynmt.helpers - cfg.training.scheduling            : noam\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.learning_rate_factor  : 0.5\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.learning_rate_warmup  : 1000\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.patience              : 8\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0002\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.batch_size            : 4096\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.batch_type            : token\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 3600\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.epochs                : 10\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 400\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100\n",
            "2020-12-23 16:29:34,918 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/endaw_transformer\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.training.overwrite             : True\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.training.shuffle               : True\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 3\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : True\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 8\n",
            "2020-12-23 16:29:34,919 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.0\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 2048\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.3\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 8\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.0\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 2048\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.3\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - Data set sizes: \n",
            "\ttrain 5800,\n",
            "\tvalid 1001,\n",
            "\ttest 1001\n",
            "2020-12-23 16:29:34,920 - INFO - joeynmt.helpers - First training example:\n",
            "\t[SRC] s@@ our@@ ce@@ _@@ sen@@ ten@@ ce\n",
            "\t[TRG] tar@@ ge@@ t@@ _@@ sen@@ ten@@ ce\n",
            "2020-12-23 16:29:34,921 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) \" (6) to (7) and (8) a (9) i\n",
            "2020-12-23 16:29:34,921 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) \" (6) to (7) and (8) a (9) i\n",
            "2020-12-23 16:29:34,921 - INFO - joeynmt.helpers - Number of Src words (types): 4003\n",
            "2020-12-23 16:29:34,921 - INFO - joeynmt.helpers - Number of Trg words (types): 4003\n",
            "2020-12-23 16:29:34,922 - INFO - joeynmt.training - Model(\n",
            "\tencoder=TransformerEncoder(num_layers=6, num_heads=8),\n",
            "\tdecoder=TransformerDecoder(num_layers=6, num_heads=8),\n",
            "\tsrc_embed=Embeddings(embedding_dim=512, vocab_size=4003),\n",
            "\ttrg_embed=Embeddings(embedding_dim=512, vocab_size=4003))\n",
            "2020-12-23 16:29:34,924 - INFO - joeynmt.training - Train stats:\n",
            "\tdevice: cpu\n",
            "\tn_gpu: 0\n",
            "\t16-bits training: False\n",
            "\tgradient accumulation: 1\n",
            "\tbatch size per device: 4096\n",
            "\ttotal batch size (w. parallel & accumulation): 4096\n",
            "2020-12-23 16:29:34,925 - INFO - joeynmt.training - EPOCH 1\n",
            "2020-12-23 16:42:02,504 - INFO - joeynmt.training - Epoch   1: total training loss 482.29\n",
            "2020-12-23 16:42:02,504 - INFO - joeynmt.training - EPOCH 2\n",
            "2020-12-23 16:46:42,451 - INFO - joeynmt.training - Epoch   2, Step:      100, Batch Loss:     6.056928, Tokens per Sec:      218, Lr: 0.000070\n",
            "2020-12-23 16:54:04,050 - INFO - joeynmt.training - Epoch   2: total training loss 428.75\n",
            "2020-12-23 16:54:04,050 - INFO - joeynmt.training - EPOCH 3\n",
            "2020-12-23 17:03:53,643 - INFO - joeynmt.training - Epoch   3, Step:      200, Batch Loss:     5.905109, Tokens per Sec:      217, Lr: 0.000140\n",
            "2020-12-23 17:06:19,476 - INFO - joeynmt.training - Epoch   3: total training loss 416.29\n",
            "2020-12-23 17:06:19,476 - INFO - joeynmt.training - EPOCH 4\n",
            "2020-12-23 17:18:31,438 - INFO - joeynmt.training - Epoch   4: total training loss 398.31\n",
            "2020-12-23 17:18:31,439 - INFO - joeynmt.training - EPOCH 5\n",
            "2020-12-23 17:20:55,661 - INFO - joeynmt.training - Epoch   5, Step:      300, Batch Loss:     5.588333, Tokens per Sec:      235, Lr: 0.000210\n",
            "2020-12-23 17:30:33,659 - INFO - joeynmt.training - Epoch   5: total training loss 383.05\n",
            "2020-12-23 17:30:33,659 - INFO - joeynmt.training - EPOCH 6\n",
            "2020-12-23 17:37:30,174 - INFO - joeynmt.training - Epoch   6, Step:      400, Batch Loss:     5.068192, Tokens per Sec:      222, Lr: 0.000280\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/joeynmt/joeynmt/__main__.py\", line 41, in <module>\n",
            "    main()\n",
            "  File \"/content/joeynmt/joeynmt/__main__.py\", line 29, in main\n",
            "    train(cfg_file=args.config_path)\n",
            "  File \"/content/joeynmt/joeynmt/training.py\", line 744, in train\n",
            "    trainer.train_and_validate(train_data=train_data, valid_data=dev_data)\n",
            "  File \"/content/joeynmt/joeynmt/training.py\", line 428, in train_and_validate\n",
            "    valid_duration = self._validate(valid_data, epoch_no)\n",
            "  File \"/content/joeynmt/joeynmt/training.py\", line 517, in _validate\n",
            "    n_gpu=self.n_gpu\n",
            "  File \"/content/joeynmt/joeynmt/prediction.py\", line 121, in validate_on_data\n",
            "    beam_alpha=beam_alpha, max_output_length=max_output_length)\n",
            "  File \"/content/joeynmt/joeynmt/search.py\", line 445, in run_batch\n",
            "    encoder_hidden=encoder_hidden)\n",
            "  File \"/content/joeynmt/joeynmt/search.py\", line 39, in greedy\n",
            "    src_mask, max_output_length, model, encoder_output, encoder_hidden)\n",
            "  File \"/content/joeynmt/joeynmt/search.py\", line 146, in transformer_greedy\n",
            "    trg_mask=trg_mask\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/joeynmt/joeynmt/model.py\", line 117, in forward\n",
            "    trg_mask=kwargs.get(\"trg_mask\", None))\n",
            "  File \"/content/joeynmt/joeynmt/model.py\", line 186, in _decode\n",
            "    trg_mask=trg_mask)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/joeynmt/joeynmt/decoders.py\", line 518, in forward\n",
            "    src_mask=src_mask, trg_mask=trg_mask)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/joeynmt/joeynmt/transformer_layers.py\", line 272, in forward\n",
            "    o = self.feed_forward(self.dropout(h2) + h1)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/joeynmt/joeynmt/transformer_layers.py\", line 116, in forward\n",
            "    return self.pwff_layer(x_norm) + x\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 117, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\", line 91, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1676, in linear\n",
            "    output = input.matmul(weight.t())\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ysDtn0Wo63G"
      },
      "source": [
        "while True:pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzPS0TYMKUBl",
        "outputId": "560b41c4-97d7-41c5-9d96-ee99fddaec2b"
      },
      "source": [
        "! cat joeynmt/models/enom_transformer/validations.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat: joeynmt/models/enom_transformer/validations.txt: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5aEBKnNKXgr"
      },
      "source": [
        "# Copy the created models from the notebook storage to google drive for persistant storage \r\n",
        "!mkdir \"$gdrive_path/models/\"\r\n",
        "!cp -r joeynmt/models/* \"$gdrive_path/models/${src}${tgt}_transformer/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGdAAl5EKZT4",
        "outputId": "a612f9ac-ec1a-415b-c304-f8f5a2978e27"
      },
      "source": [
        "! cat \"$gdrive_path/models/${src}${tgt}_transformer/validations.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps: 400\tLoss: 145913.60938\tPPL: 157.19530\tbleu: 0.06422\tLR: 0.00027951\t*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH6IkZa7Kape",
        "outputId": "e87044cb-1e72-46aa-dd89-bc72225df8f4"
      },
      "source": [
        "! cd joeynmt; python3 -m joeynmt test models/enom_transformer/config.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/joeynmt/joeynmt/__main__.py\", line 41, in <module>\n",
            "    main()\n",
            "  File \"/content/joeynmt/joeynmt/__main__.py\", line 32, in main\n",
            "    output_path=args.output_path, save_attention=args.save_attention)\n",
            "  File \"/content/joeynmt/joeynmt/prediction.py\", line 267, in test\n",
            "    cfg = load_config(cfg_file)\n",
            "  File \"/content/joeynmt/joeynmt/helpers.py\", line 176, in load_config\n",
            "    with open(path, 'r') as ymlfile:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'models/enom_transformer/config.yaml'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZBgnCjS2R6H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}